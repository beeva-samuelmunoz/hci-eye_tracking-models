{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import config\n",
    "from utils import data_model\n",
    "from utils.model import Model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, imgs_left, imgs_right = data_model.load(\n",
    "    config.PATH_DATA_FEATURES01_DLIB_AUGMENTED_NORM_CSV,\n",
    "    config.PATH_DATA_FEATURES01_DLIB_AUGMENTED_NORM_IMGS_LEFT,\n",
    "    config.PATH_DATA_FEATURES01_DLIB_AUGMENTED_NORM_IMGS_RIGHT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    (train_data, train_imgs_left, train_imgs_right),\n",
    "    (validation_data, validation_imgs_left, validation_imgs_right),\n",
    "    (test_data, test_imgs_left, test_imgs_right)\n",
    ") = data_model.split(\n",
    "    data, imgs_left, imgs_right,\n",
    "    train_size=0.95,\n",
    "    validation_size=0.95,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Train length: {}\".format(len(train_data)))\n",
    "print(\"Validation length: {}\".format(len(validation_data)))\n",
    "print(\"Test length: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/models/02-baseline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(features, left_imgs, right_imgs, *args, **kwargs):\n",
    "    with tf.variable_scope('model'):\n",
    "        left_flat = tf.contrib.layers.flatten (left_imgs)\n",
    "        right_flat =  tf.contrib.layers.flatten (right_imgs)\n",
    "        flat_input = tf.concat(\n",
    "            values=[features, left_flat, right_flat],\n",
    "            axis=1,\n",
    "            name='concat'\n",
    "        )\n",
    "        # 12+(20x30)x2 = 1212 inputs\n",
    "        d1 = tf.layers.dense(flat_input, 1024, activation=tf.nn.relu)\n",
    "        d2 = tf.layers.dense(d1, 512, activation=tf.nn.relu)\n",
    "        d3 = tf.layers.dense(d2, 128, activation=tf.nn.relu)\n",
    "        d4 = tf.layers.dense(d3, 2, activation=None)\n",
    "    return d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Parameters to adjust: {}\".format( \n",
    "    ((20*30*2)+12)*1024 +\n",
    "    1024*512+\n",
    "    512*128+\n",
    "    128*2\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'baseline-07'\n",
    "\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(MODEL_NAME, get_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train(\n",
    "    train_data, train_imgs_left, train_imgs_right,\n",
    "    validation_data, validation_imgs_left, validation_imgs_right,\n",
    "    BATCH_SIZE, EPOCHS, LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_test = Model(MODEL_NAME, saved_model=MODEL_NAME+\".final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test.test(\n",
    "    test_data, test_imgs_left, test_imgs_right\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "\n",
    "| Name | Epochs | Batch Size | Learning rate  | Train | Validation | Test |\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| baseline-01 | 20 | 512 | 0.005 | 0.14687612652778625 | 0.1866748034954071 | 0.19118537 |\n",
    "| baseline-02 | 25 | 256 | 0.001 | 0.07768817245960236 | 0.1376853734254837 | 0.13483852 |\n",
    "| baseline-03 | 40 | 256 | 0.0001 | 0.048277597874403 | 0.14694760739803314 | 0.14895809  |\n",
    "| baseline-04 | 100 | 512 | 0.0001 | 0.031881727278232574 | 0.14400143921375275 | 0.14583308 |\n",
    "| baseline-05 | 200 | 1024 | 0.0001 | 0.028280340135097504 | 0.14690683782100677 | 0.15199703 |\n",
    "| baseline-06 | 100 | 256| 0.0005 | 0.03301012143492699 | 0.11154743283987045 | 0.11112656 |\n",
    "| baseline-07 | 40 | 128| 0.0005 | 0.05355171859264374 | 0.12075861543416977 | 0.12119327 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First iteration\n",
    "\n",
    "* Half of the augmented images had the wrong 'x' label.\n",
    "\n",
    "| Name | Epochs | Batch Size | Learning rate  | Train | Validation | Test |\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| baseline-01 | 20 | 512 | 0.005 | 0.1395065039396286 | 0.19760280847549438 | 0.19909994 |\n",
    "| baseline-02 | 25 | 256 | 0.001 | 0.07893882691860199 | 0.15243780612945557 | 0.15074611 |\n",
    "| baseline-02 | 25 | 256 | 0.001 | 0.07598952203989029 | 0.14176610112190247 | 0.14149468 |\n",
    "| baseline-03 | 40 | 256 | 0.0001 | 0.057024769484996796 | 0.1646086573600769 | 0.16265412 |\n",
    "| baseline-04 | 100 | 512 | 0.0001 | 0.03750447556376457 | 0.1642383337020874 | 0.16351545 |\n",
    "| baseline-05 | 200 | 1024 | 0.0001 | 0.029262783005833626 | 0.1729333996772766 | 0.17122823 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
