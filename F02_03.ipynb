{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Baseline\n",
    "## Library: Keras\n",
    "## Dataset: Features02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import config\n",
    "from utils import data_model\n",
    "from utils.keras import losses\n",
    "from utils.features02_dlib import FEATURES, TARGETS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.contrib import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, imgs_left, imgs_right = data_model.load(\n",
    "    config.PATH_DATA_FEATURES02_DLIB_AUGMENTED_NORM_CSV,\n",
    "    config.PATH_DATA_FEATURES02_DLIB_AUGMENTED_NORM_IMGS_LEFT,\n",
    "    config.PATH_DATA_FEATURES02_DLIB_AUGMENTED_NORM_IMGS_RIGHT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    (train_data, train_imgs_left, train_imgs_right),\n",
    "    (validation_data, validation_imgs_left, validation_imgs_right),\n",
    "    (test_data, test_imgs_left, test_imgs_right)\n",
    ") = data_model.split(\n",
    "    data, imgs_left, imgs_right,\n",
    "    train_size=0.95,\n",
    "    validation_size=0.95,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Train length: {}\".format(len(train_data)))\n",
    "print(\"Validation length: {}\".format(len(validation_data)))\n",
    "print(\"Test length: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width, img_height = config.FEATURES02_EYES_SIZE\n",
    "img_shape = (img_height, img_width)\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    # Inputs\n",
    "    left_imgs = keras.layers.Input(shape=img_shape, name='left_imgs', dtype='float32')\n",
    "    right_imgs = keras.layers.Input(shape=img_shape, name='right_imgs', dtype='float32')\n",
    "    features = keras.layers.Input(shape=(len(FEATURES),), name='features', dtype='float32')\n",
    "    # Left imgs\n",
    "    l1 = keras.layers.Dense(512, activation=keras.activations.relu)(keras.layers.Flatten()(left_imgs))\n",
    "    l2 = keras.layers.Dense(256, activation=keras.activations.relu)(l1)\n",
    "    l3 = keras.layers.Dense(128, activation=keras.activations.relu)(l2)\n",
    "    ld = keras.layers.Dropout(DROPOUT)(l3)\n",
    "    # Right imgs\n",
    "    r1 = keras.layers.Dense(512, activation=keras.activations.relu)(keras.layers.Flatten()(right_imgs))\n",
    "    r2 = keras.layers.Dense(256, activation=keras.activations.relu)(r1)\n",
    "    r3 = keras.layers.Dense(128, activation=keras.activations.relu)(r2)\n",
    "    rd = keras.layers.Dropout(DROPOUT)(r3)\n",
    "    # Features\n",
    "    f1 = keras.layers.Dense(128, activation=keras.activations.relu)(features)\n",
    "    f2 = keras.layers.Dense(64, activation=keras.activations.relu)(f1)\n",
    "    # Concatenate\n",
    "    concat = keras.layers.Concatenate()([ld,rd,f2])\n",
    "    # Dense\n",
    "    d_1 = keras.layers.Dense(512, activation=keras.activations.relu)(concat)\n",
    "    d_2 = keras.layers.Dense(128, activation=keras.activations.relu)(d_1)\n",
    "    d_3 = keras.layers.Dense(32, activation=keras.activations.relu)(d_2)\n",
    "    d_4 = keras.layers.Dense(2)(d_3)\n",
    "    # Model\n",
    "    model = keras.models.Model(\n",
    "        inputs=[left_imgs, right_imgs, features],\n",
    "        outputs=[d_4]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'f02_03-06'\n",
    "\n",
    "EPOCHS = 300\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.005\n",
    "DECAY = 0.0001\n",
    "DROPOUT = 0.01\n",
    "\n",
    "LOSS = losses.mean_euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=LOSS,\n",
    "    metrics=[losses.mean_euclidean],\n",
    "    optimizer=keras.optimizers.Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=DECAY)\n",
    ")\n",
    "\n",
    "print(\"Parameters to adjust: {}\".format(\n",
    "    np.sum([keras.backend.count_params(p) for p in set(model.trainable_weights)])\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x={\n",
    "        'left_imgs':train_imgs_left,\n",
    "        'right_imgs': train_imgs_right,\n",
    "        'features': train_data[FEATURES].as_matrix()\n",
    "    },\n",
    "    y=train_data[TARGETS].as_matrix(),\n",
    "    validation_data=(\n",
    "        {\n",
    "            'left_imgs': validation_imgs_left,\n",
    "            'right_imgs': validation_imgs_right,\n",
    "            'features': validation_data[FEATURES].as_matrix()\n",
    "        },\n",
    "        validation_data[TARGETS].as_matrix()\n",
    "    ),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=1, callbacks=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(config.PATH_MODELS_KERAS+MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_test = keras.models.load_model(\n",
    "    filepath=config.PATH_MODELS_KERAS+MODEL_NAME,\n",
    "    custom_objects={\n",
    "        \"mean_euclidean\": losses.mean_euclidean,\n",
    "        \"ms_euclidean\": losses.ms_euclidean,\n",
    "        \"reg_mean_euclidean\": losses.reg_mean_euclidean\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(\n",
    "    x={\n",
    "        'left_imgs':test_imgs_left,\n",
    "        'right_imgs': test_imgs_right,\n",
    "        'features': test_data[FEATURES].as_matrix()\n",
    "    },\n",
    "    y=test_data[TARGETS].as_matrix(),\n",
    "    batch_size=1,\n",
    "    verbose=1, sample_weight=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.12337\n",
    "0.1164\n",
    "0.1784\n",
    "0.179\n",
    "\n",
    "[0.2070697691578548, 0.2070697691578548]\n",
    "loss: 0.0319 - mean_euclidean: 0.0319 - val_loss: 0.1428 - val_mean_euclidean: 0.1428\n",
    "                \n",
    "\n",
    "128*64*2  +16 > 256*64*31*2\n",
    "                \n",
    "68 pts\n",
    "loss: 0.0338 - mean_euclidean: 0.0338 - val_loss: 0.1626 - val_mean_euclidean: 0.1626\n",
    "0.1661774875152163\n",
    "\n",
    "facepoints\n",
    "0.0368 - mean_euclidean: 0.0368 - val_loss: 0.1659 - val_mean_euclidean: 0.1659\n",
    "0.17\n",
    "\n",
    "\n",
    "68\n",
    "mean_euclidean: 0.0196 - val_loss: 0.1443 - val_mean_euclidean: 0.1443\n",
    "0.14271\n",
    "\n",
    "tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Corrected dataset\n",
    "\n",
    "\n",
    "| Name | Epochs | Batch Size | Learning rate | Decay | Loss | Train | Validation | Test |\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| baseline-08a2 | 150 | 128| 0.0005 | 0.00001 | mean_euclidean | 0.0306 | 0.1286 | 0.1245 |\n",
    "| f02_baseline-09 | 150 | 128| 0.0005 | 0.00001 | mean_euclidean | 0.0384 | 0.1205 | 0.1182 |\n",
    "| f02_baseline-10 | 150 | 128| 0.0005 | 0.00001 | ms_euclidean | 0.0016 | 0.0234 | 0.02287 |\n",
    "| f02_baseline-13 | 150 | 128| 0.0005 | 0.00001 | mean_euclidean | 0.0381 | 0.1197 | 0.1199 |\n",
    "| f02_baseline-14 | 150 | 128| 0.0005 | 0.00001 | ms_euclidean | 0.0355 | 0.1176 |  |\n",
    "| f02_baseline-15 | 150 | 128| 0.0005 | 0.00001 | reg_mean_euclidean | 0.0425 | 0.1214 | 0.12201 |\n",
    "| f02_baseline-16 | 400 | 128| 0.0001 | 0.00001 | reg_mean_euclidean | 0.0215 | 0.1279 | 0.1287 |\n",
    "| f02_baseline-18x | 300 | 128| 0.0005 | 0.00001 | mean_euclidean | 0.0236 | 0.1123 | 0.1116 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(test_data[FEATURES].as_matrix()[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(scaler.transform(train_data[FEATURES])[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "predictions = model_test.predict(\n",
    "    x={\n",
    "        'left_imgs':test_imgs_left,\n",
    "        'right_imgs': test_imgs_right,\n",
    "        'features': scaler.transform(test_data[FEATURES]),\n",
    "        #'features': test_data[FEATURES].as_matrix()\n",
    "    }\n",
    ")\n",
    "errors = test_data[TARGETS].as_matrix()-predictions\n",
    "sns.jointplot(x=errors[:,0], y=errors[:,1], kind=\"kde\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
